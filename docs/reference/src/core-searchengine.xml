<chapter id="core-searchengine">
  <title>Search Engine</title>

  <sect1 id="core-searchengine-introduction">
    <title>Introduction</title>

    <para>
      Compass Core provides an abstraction layer on top of the wonderful <ulink url="http://lucene.apache.org">Lucene</ulink> Search Engine. Compass also provides several additional features on top of Lucene, like two phase transaction management, fast updates, and optimizers. When trying to explain how Compass works with the Search Engine, first we need to understand the Search Engine domain model.
    </para>
  </sect1>

  <sect1 id="core-searchengine-AliasResourceProperty">
    <title>Alias, Resource and Property</title>

    <para>
      <literal>Resource</literal> represents a collection of properties. You can think about it as a virtual document - a chunk of data, such as a web page, an email message, or a serialization of the Author object. A <literal>Resource</literal> is always associated with a single Alias and
      several <literal>Resource</literal>s can have the same Alias. The alias acts as the connection between a <literal>Resource</literal> and its mapping definitions (OSEM/XSEM/RSEM). A <literal>Property</literal> is just a place holder for a name and value (both strings). A <literal>Property</literal> within a <literal>Resource</literal> represents some kind of meta-data that is associated with the
      <literal>Resource</literal> like the author name. 
    </para>

    <para>
      Every <literal>Resource</literal> is associated with one or more id properties. They are required for Compass to manage <literal>Resource</literal> loading based on ids and <literal>Resource</literal>
      updates (a well known difficulty when using Lucene directly). Id properties are defined either explicitly in RSEM definitions or implicitly in OSEM/XSEM definitions.
    </para>

    <para>
      For Lucene users, Compass <literal>Resource</literal> maps to Lucene <literal>Document</literal> and Compass <literal>Property</literal> maps to Lucene <literal>Field</literal>.
    </para>

    <sect2 id="core-searchengine-arp-using">
      <title>Using Resource/Property</title>

      <para>
        When working with RSEM, resources acts as your prime data model. They are used to construct searchable content, as well as manipulate it. When performing a search, resources be used to display the search results.
      </para>

      <para>
        Another important place where resources can be used, which is often ignored, is with OSEM/XSEM. When manipulating search content through the use of the application domain model (in case of OSEM), or through the use of xml data structures (in case of XSEM), resources are rarely used. They can be used when performing search operations. Based on your mapping definition, the semantic model could be accessed in a uniformed way through resources and properties.
      </para>

      <para>
        Lets simplify this statement by using an example. If our application has two object types, Recipe and Ingredient, we can map both recipe title and ingredient title into the same semantic meta-data name, <literal>title</literal> (Resource Property name). This will allow us when searching to display the search results (hits) only on the Resource level, presenting the value of the property title from the list of resources returned.
      </para>
    </sect2>

  </sect1>

  <sect1 id="core-searchengine-analyzers">
    <title>Analyzers</title>

    <para>
      <literal>Analyzer</literal>s are components that pre-process input text. They are also used when searching (the search string has to be processed the same way that the indexed text was processed). Therefore, it is usually important to use the same <literal>Analyzer</literal> for both indexing and searching.
    </para>

    <para>
      <literal>Analyzer</literal> is a Lucene class (which qualifies to <literal>org.apache.lucene.analysis.Analyzer</literal> class). Lucene core itself comes with several <literal>Analyzer</literal>s and you can configure Compass to work with either one of them. If we take the following sentence: "The quick brown fox jumped over the lazy dogs", we can see how the different <literal>Analyzer</literal>s handle it:
      
<programlisting><![CDATA[
whitespace (org.apache.lucene.analysis.WhitespaceAnalyzer):
  [The] [quick] [brown] [fox] [jumped] [over] [the] [lazy] [dogs]
  
simple (org.apache.lucene.analysis.SimpleAnalyzer):
  [the] [quick] [brown] [fox] [jumped] [over] [the] [lazy] [dogs]
  
stop (org.apache.lucene.analysis.StopAnalyzer):
  [quick] [brown] [fox] [jumped] [over] [lazy] [dogs]

standard (org.apache.lucene.analysis.standard.StandardAnalyzer):
  [quick] [brown] [fox] [jumped] [over] [lazy] [dogs]
]]></programlisting>

    </para>
    
    <para>
      Lucene also comes with an extension library, holding many more analyzer implementations (including language specific analyzers). Compass can be configured to work with all of them as well.
    </para>
    
    <sect2 id="core-searchengine-analyzers-config">
      <title>Configuring Analyzers</title>
      
      <para>
        A Compass instance acts as a registry of analyzers, with each analyzer bound to a lookup name. Two internal analyzer names within Compass are: <literal>deafult</literal> and <literal>search</literal>. <literal>default</literal> is the default analyzer that is used when no other analyzer is configured (configuration of using different analyzer is usually done in the mapping definition by referencing a different analyzer lookup name). <literal>search</literal> is the analyzer used on a search query string when no other analyzer is configured (configuring a different analyzer when executing a search based on a query string is done through the query builder API). By default, when nothing is configured, Compass will use Lucene standard analyzer as the <literal>default</literal> analyzer.
      </para>
      
      <para>
        The following is an example of configuring two analyzers, one that will replace the <literal>deafult</literal> analyzer, and another one registered against <literal>myAnalyzer</literal> (it will probably later be referenced from within the different mapping definitions).
<programlisting><![CDATA[<compass name="default">

    <connection>
        <file path="target/test-index" />
    </connection>

    <searchEngine>
        <analyzer name="deault" type="Snowball" snowballType="Lovins">
            <stopWords>
                <stopWord value="no" />
            </stopWords>
        </analyzer>
        <analyzer name="myAnalyzer" type="Standard" />
    </searchEngine>
</compass>
]]></programlisting>
      </para>
      
      <para>
        Compass also supports custom implementations of Lucene <classname>Analyzer</classname> class (note, the same goal might be acheived by implementing an analyzer filter, described later). If the implementation also implements <classname>CompassConfigurable</classname>, additional settings (parameteres) can be injected to it using the configuration file. Here is an example configuration that registeres a custom analyzer implementation that accepts a parameter named threshold:
<programlisting><![CDATA[<compass name="default">

    <connection>
        <file path="target/test-index" />
    </connection>

    <searchEngine>
        <analyzer name="deault" type="CustomAnalyzer" analyzerClass="eg.MyAnalyzer">
          <setting name="threshold">5</setting>
        </analyzer>
    </searchEngine>
</compass>
]]></programlisting>
      </para>
    </sect2>
    
    <sect2 id="core-searchengine-analyzers-filter">
      <title>Analyzer Filter</title>
      
      <para>
        Filters are provided for simpler support for additional filtering (or enrichment) of analyzed streams, without the hassle of creating your own analyzer. Also, filters, can be shared across different analyzers, potentially having different analyzer types.
      </para>
      
      <para>
        A custom filter implementation need to implement Compass <classname>LuceneAnalyzerTokenFilterProvider</classname>, which single method creates a Lucene <classname>TokenFilter</classname>. Filteres are registered against a name as well, which can then be used in the analyzer configuration to reference them. The next example configured two analyzer filters, which are applied on to the <literal>default</literal> analyzer:
<programlisting><![CDATA[<compass name="default">

  <connection>
      <file path="target/test-index" />
  </connection>

  <searchEngine>
      <analyzer name="deafult" type="Standard" filters="test1, test2" />
      
      <analyzerFilter name="test1" type="eg.AnalyzerTokenFilterProvider1">
          <setting name="param1" value="value1" />
      </analyzerFilter>
      <analyzerFilter name="test2" type="eg.AnalyzerTokenFilterProvider2">
          <setting name="paramX" value="valueY" />
      </analyzerFilter>
  </searchEngine>
</compass>
]]></programlisting>
      </para>
    </sect2>
    
    <sect2 id="core-searchengine-analyzers-synonym">
      <title>Handling Synonyms</title>
      
      <para>
        Since synonyms are a common requirement with a search application, Compass comes with a simple synonym analyzer filter: <classname>SynonymAnalyzerTokenFilterProvider</classname>. The implementation requires as a parameter (setting) an implementation of a <classname>SynonymLookupProvider</classname>, which can return all the synonyms for a given value. No implementation is provided, though one that goes to a public synonym database, or a file input structure is simple to implement. Here is an example of how to configure it:
<programlisting><![CDATA[<compass name="default">

  <connection>
      <file path="target/test-index" />
  </connection>

  <searchEngine>
      <analyzer name="deafult" type="Standard" filters="synonymFilter" />
      
      <analyzerFilter name="synonymFilter" type="synonym">
          <setting name="lookup" value="eg.MySynonymLookupProvider" />
      </analyzerFilter>
  </searchEngine>
</compass>
]]></programlisting>
      </para>
      
      <para>
        Note the fact that we did not set the fully qualified class name for the type, and used <literal>synonym</literal>. This is a simplification that comes with Compass (naturally, you can still use the fully qualified class name of the synonym token filter provider).
      </para>
    </sect2>
  </sect1>

  <sect1 id="core-searchengine-indexstructure">
    <title>Index Structure</title>

    <para>
      It is very important to understand how the Search Engine index is organized so we can than talk about transaction and optimizers. The following structure shows the Search Engine Index Structure:
<programlisting><![CDATA[---[index dir]/index
  |
  |-- [subIndex1]
  |      |
  |      |--- segments
  |      |--- [segment1]
  |      |--- [segment2]
  |
  |-- [subIndex2]
  |      |
  |      |--- segments
  |      |--- [segment1]
  |      |--- [segment2]
  |      |--- [segment3]
  |
...
]]></programlisting>
    </para>

    <para>
        Every sub-index has it's own fully functional index structure (which maps to a single Lucene index). Each <literal>Resource</literal> alias is associated with a sub-index, and more than one alias can be mapped to a sub-index (using either resource mapping or OSEM). The Lucene index part holds a "meta data" file about the index (called <literal>segments</literal>) and 0 to N segment files. The segments can be a single file (if the compound setting is enabled) or multiple files (if the compound setting is disable). A segment is close to a fully functional index, which hold the actual inverted index data (see <ulink url="http://lucene.apache.org">Lucene</ulink> documentation for a detailed description of these concepts).
    </para>
  </sect1>

  <sect1 id="core-searchengine-transaction">
    <title>Transaction</title>

    <para>
      Compass:Core Search Engine abstraction provides support for transaction management on top of Lucene. The abstraction support common transaction levels: <literal>read_committed</literal> and <literal>serializable</literal>, as well as the special <literal>batch_insert</literal> one. Compass::Core provides two phase commit support for the common transaction levels only.
    </para>

        <sect2 id="Locking">
            <title>Locking</title>

            <para>
                Compass::Core utilizes Lucene inter and outer process locking mechanism and uses them to establish it's transaction locking. Note that the transaction locking is on the "sub-index" level (the sub-
                index based index), which means that dirty operations only lock their respective sub-index index. So the more aliases map to the same index, the more aliases will be locked when performing dirty operations, yet
                the faster the searches will be. Lucene uses a special lock file to manage the inter and outer process locking which can be set in the Compass::Core configuration. You can manage the transaction timeout and polling interval using the Compass::Core configuration.
            </para>

            <para>
                The Compass::Core transaction acquires a lock only when a dirty (i.e. <literal>create</literal>, <literal>save</literal> or <literal>delete</literal>) operation occurs, which makes "read only" transactions as fast as they should and can be.
            </para>

        </sect2>

        <sect2 id="read_committed">
            <title>read_committed</title>

            <para>
                Compass::Core provides support for <literal>read_committed</literal> transaction level. When starting a <literal>read_committed</literal> transaction, no locks are obtained. Read operation will not obtain a
                lock either. A lock will be obtained only when a dirty operation is performed. The lock is obtained only on the index of the alias that is associated with the dirty operation, i.e the sub-index, and will lock
                all other aliases that map to that sub-index. In Compass::Core, every transaction that performed one or more <literal>save</literal> or <literal>create</literal> operation, and committed successfully,
                creates another segment in the respective index (different than how Lucene manages it's index), which helps in implementing quick transaction commits, as well as paving the way for a two phase commit support (and the reason behind having optimizers).
            </para>

        </sect2>

        <sect2 id="serializable">
            <title>serializable</title>

            <para>
                The <literal>serializable</literal> transaction level operates the same as the <literal>read_committed</literal> transaction level, except that when the transaction is opened/started, a lock is acquired
                on all the sub-indexes. This causes the transactional operations to be sequential in nature (as well as being a performance killer).
            </para>
        </sect2>

        <sect2 id="batch_insert">
            <title>batch_insert</title>

            <para>
                A special transaction level, <literal>batch_insert</literal> utilizes the extremely fast batch indexing provided by Lucene. The transaction supports only <literal>create</literal> operation, but note that if
                another <literal>Resource</literal> with the same alias and ids already exists in the system, you will have two instances of it in the index (in other words, <literal>create</literal> doesn't delete the
                old <literal>Resource</literal>). You can control the <literal>batch_insert</literal> transaction using several settings which are explained in the Configuration section. An important note is that the
                transaction is not a transaction which can be rolled back, since Lucene commits the changes during the batch indexing process, which means that a <literal>rollback</literal> operation won't rollback the
                changes. The index is optimized when the transaction is committed, which means that all the segments are merged to one segment, in order to provide fast searching. The transaction is mainly used for background batch indexing.
            </para>

        </sect2>

  </sect1>

  <sect1 id="core-searchengine-optimizers">
    <title>Optimizers</title>

    <para>
      As mentioned in the <literal>read_committed</literal> section, every dirty transaction that is committed successfully creates another segment in the respective index. The more segments the index has, the slower the fetching operations take. That's why it is important to keep the index optimized and with a controlled number of segments. We do this by merging small segments into larger segments.
    </para>

    <para>
      In order to solve the problem, Compass::Core has a <literal>SearchEngineOptimizer</literal> which is responsible for keeping the number of segments at bay. When <literal>Compass</literal> is built using
      <literal>CompassConfiguration</literal>, the <literal>SearchEngineOptimizer</literal> is started and when the <literal>Compass</literal> is closed, the <literal>SearchEngineOptimizer</literal> is
      stopped.
    </para>

    <sect2 id="ScheduledOptimizers">
      <title>Scheduled Optimizers</title>
      <para>
        Compass::Core provides support for scheduled optimizers. The scheduled optimizers uses Java <literal>Timer</literal> to control it's execution. <literal>SearchEngineOptimizer</literal> starts and stops the
        timer when it starts and stops. There are several settings parameters that can be set to control the scheduling.
      </para>

      <para>
        Note: each optimizer that Compass provides can be scheduled.
      </para>

    </sect2>

    <sect2 id="AggressiveOptimizer">
      <title>Aggressive Optimizer</title>

      <para>
        The <literal>AggressiveOptimizer</literal> uses Lucene optimization feature to optimize the index. Lucene optimization merges all the segments into one segment. You can set the limit of the number of
        segments, after which the index is considered to need optimization (the aggressive optimizer merge factor).
      </para>

    </sect2>

    <sect2 id="AdaptiveOptimizer">
      <title>Adaptive Optimizer</title>

      <para>
        The <literal>AdaptiveOptimizer</literal> uses optimize the segments while trying to manage the optimization time at bay. As an example, when we have a large segment in our index (for example, after we batched indexed the data), and we perform several interactive transactions, the
        aggressive optimizer will than merge all the segments together, while the adaptive optimizer will only merge the new small segments. You can set the limit of the number of segments, after which the index is considered to need optimization (the adaptive optimizer merge factor).
      </para>

    </sect2>

    <sect2 id="NullOptimizer">
      <title>Null Optimizer</title>

      <para>
        Compass::Core also comes with a <literal>NullOptimizer</literal>, which performs no optimizations. It is mainly there if the hosting application developed it's own optimization which is maintained by other
        means than the <literal>SearchEngineOptimizer</literal>. It also makes sense to use it when configuring a <literal>Compass</literal> instance with a <literal>batch_insert</literal> transaction.
      </para>

      <para>
        Note that when using the <literal>NullOptimizer</literal> it makes no sense to use the scheduling feature, so remember to set the <literal>compass.engine.optimizer.schedule</literal> to <literal>false</literal>.

      </para>

    </sect2>

  </sect1>

</chapter>






